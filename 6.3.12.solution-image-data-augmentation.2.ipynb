{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solution_image_data_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32-zMt7tZr3R"
      },
      "source": [
        "# Solution: Image Data Augmentation\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ShawnHymel/computer-vision-with-embedded-machine-learning/blob/master/2.3.5%20-%20Project%20-%20Data%20Augmentation/solution_image_data_augmentation.ipynb)\n",
        "\n",
        "This is an example for creating an augmented dataset. It will transform input images to create a series of augmented samples that are saved in a new output directory.\n",
        "\n",
        "Create a folder named \"dataset\" in the /content directory and upload your images there. The images should be divided into their respective classes, where each class has its own folder with the name of the class. For example:\n",
        "\n",
        "<pre>\n",
        "/content\n",
        "    |- dataset\n",
        "        |- background\n",
        "        |- capacitor\n",
        "        |- diode\n",
        "        |- led\n",
        "        |- resistor\n",
        "</pre>\n",
        "\n",
        "The original images along with their transforms will be saved in the output directory. Each output file will be the original filename appended with \"_{num}\" where {num} is some incrementing value based on the total number of transforms performed per image.\n",
        "\n",
        "For example, if you have a file named \"0.png\" in /content/dataset/resistor, it will become \"0_0.png\" in /content/output/resistor. The first transform will be \"0_1.png\", the second transform will be \"0_2.png\" and so on.\n",
        "\n",
        "Run each of the cells paying attention to their contents and output. Fill out the necessary parts of the functions where you find the following comment:\n",
        "\n",
        "```\n",
        "# >>> ENTER YOUR CODE HERE <<<\n",
        "```\n",
        "\n",
        "Author: EdgeImpulse, Inc.<br>\n",
        "Date: August 3, 2021<br>\n",
        "License: [Apache-2.0](apache.org/licenses/LICENSE-2.0)<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTimcB-ZoIT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "import skimage.transform\n",
        "import skimage.util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJCNZmEaCCN"
      },
      "source": [
        "### Settings\n",
        "\n",
        "# Location of dataset and output folder\n",
        "DATASET_PATH = \"/content/dataset\"\n",
        "OUT_PATH = \"/content/output\"\n",
        "OUT_ZIP = \"augmented_dataset.zip\"\n",
        "\n",
        "# File format to use for new dataset\n",
        "IMG_EXT = \".png\"\n",
        "\n",
        "# You are welcome to change the seed to get different augmentation effects\n",
        "SEED = 42\n",
        "random.seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siLr8t4-qR9K"
      },
      "source": [
        "### Create output directory\n",
        "try:\n",
        "  os.makedirs(OUT_PATH)\n",
        "except FileExistsError:\n",
        "  print(\"WARNING: Output directory already exists. Check to make sure it is empty.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAZYWLFeB9vR"
      },
      "source": [
        "## Transform Functions\n",
        "\n",
        "Create one or more functions that transform an input image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxh8f4JXgnTa"
      },
      "source": [
        "### Example: Function to create 3 new flipped images of the input\n",
        "def create_flipped(img):\n",
        "\n",
        "  # Create a list of flipped images\n",
        "  flipped = []\n",
        "  flipped.append(np.fliplr(img))\n",
        "  flipped.append(np.flipud(img))\n",
        "  flipped.append(np.flipud(np.fliplr(img)))\n",
        "\n",
        "  return flipped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAIqA5xdtt_6"
      },
      "source": [
        "# >>> ENTER YOUR CODE HERE <<<\n",
        "# Create one or more functions that create transforms of your images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96_3m50XhDww"
      },
      "source": [
        "### Function to create new rotated images of the input\n",
        "def create_rotated(img, rotations):\n",
        "\n",
        "  # Create list of rotated images (keep 8-bit values)\n",
        "  rotated = []\n",
        "  for rot in rotations:\n",
        "    img_rot = skimage.transform.rotate(img, angle=rot, mode='edge', preserve_range=True)\n",
        "    img_rot = img_rot.astype(np.uint8)\n",
        "    rotated.append(img_rot)\n",
        "\n",
        "  return rotated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNmLBQtmg9rT"
      },
      "source": [
        "### Function to create random scale/crop (zoom) images\n",
        "def create_random_zooms(img, scale_factor, num_crops):\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create scaled images (e.g. make the image bigger) and keep 8-bit values\n",
        "  img_scaled = skimage.transform.rescale(img, \n",
        "                                        scale=scale_factor, \n",
        "                                        anti_aliasing=True, \n",
        "                                        multichannel=True,\n",
        "                                        preserve_range=True)\n",
        "  img_scaled = img_scaled.astype(np.uint8)\n",
        "\n",
        "  # Get height and width of scaled image\n",
        "  s_h = img_scaled.shape[0]\n",
        "  s_w = img_scaled.shape[1]\n",
        "\n",
        "  # Create list of random zooms\n",
        "  zooms = []\n",
        "  for i in range(num_crops):\n",
        "    \n",
        "    # Randomly choose start of crop point\n",
        "    crop_y = round(random.random() * (s_h - height))\n",
        "    crop_x = round(random.random() * (s_w - width))\n",
        "\n",
        "    # Crop scaled image\n",
        "    zoom = img_scaled[crop_y:(crop_y + height), crop_x:(crop_x + width), :]\n",
        "\n",
        "    # Append zoomed image to list\n",
        "    zooms.append(zoom)\n",
        "\n",
        "  return zooms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b55wy1q69-xY"
      },
      "source": [
        "### Function to create a random set of translated images (no more than 1/4 of width or height away)\n",
        "def create_random_translations(img, num_translations):\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create list of random translations\n",
        "  translations = []\n",
        "  for i in range(num_translations):\n",
        "  \n",
        "    # Choose random amount to translate (up to 1/4 image width, height) in either direction\n",
        "    tr_y = round((0.5 - random.random()) * (height / 2))\n",
        "    tr_x = round((0.5 - random.random()) * (width / 2))\n",
        "\n",
        "    # Perform translation to create new image\n",
        "    translation = skimage.transform.AffineTransform(translation=(tr_y, tr_x))\n",
        "    img_tr = skimage.transform.warp(img, translation, mode='edge', preserve_range=True)\n",
        "    img_tr = img_tr.astype(np.uint8)\n",
        "\n",
        "    # Append translated image to list\n",
        "    translations.append(img_tr)\n",
        "\n",
        "  return translations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad0IR6Pc_n9b"
      },
      "source": [
        "### Function to add random noise to images\n",
        "def create_noisy(img, types, seed=None):\n",
        "\n",
        "  # Add noise of different types\n",
        "  noisy_imgs = []\n",
        "  for t in types:\n",
        "    noise = skimage.util.random_noise(img, mode=t, seed=seed)\n",
        "    noise = (noise * 255).astype(np.uint8)\n",
        "    noisy_imgs.append(noise)\n",
        "\n",
        "  return noisy_imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaJR7hAOCEID"
      },
      "source": [
        "## Perform Transforms\n",
        "\n",
        "Call your functions to create a set of augmented data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ryKQeQaOKE"
      },
      "source": [
        "### Function to open image and create a list of new transforms\n",
        "# NOTE: You will need to call your functions here!\n",
        "def create_transforms(file_path):\n",
        "\n",
        "  # Open the image\n",
        "  img = PIL.Image.open(file_path)\n",
        "\n",
        "  # Convert the image to a Numpy array (keep all color channels)\n",
        "  img_array = np.asarray(img)\n",
        "\n",
        "  # Add original image to front of list\n",
        "  img_tfs = []\n",
        "  img_tfs.append([img_array])\n",
        "\n",
        "  # Perform transforms (call your functions)\n",
        "  img_tfs.append(create_flipped(img_array))\n",
        "  # >>> ENTER YOUR CODE HERE <<<\n",
        "  # e.g. img_tfs.append(create_translations(img_array, 2))\n",
        "  img_tfs.append(create_flipped(img_array))\n",
        "  img_tfs.append(create_rotated(img_array, [45, 90, 135]))\n",
        "  img_tfs.append(create_random_zooms(img_array, 1.3, 2))\n",
        "  img_tfs.append(create_random_translations(img_array, 2))\n",
        "  img_tfs.append(create_noisy(img_array, ['gaussian', 's&p'], SEED))\n",
        "\n",
        "  # Flatten list of lists (to create one long list of images)\n",
        "  img_tfs = [img for img_list in img_tfs for img in img_list]\n",
        "\n",
        "  return img_tfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3ZEsAGUAvUS"
      },
      "source": [
        "### Load all images, create transforms, and save in output directory\n",
        "\n",
        "# Find the directories in the dataset folder (skip the Jupyter Notebook checkpoints hidden folder)\n",
        "for label in os.listdir(DATASET_PATH):\n",
        "  class_dir = os.path.join(DATASET_PATH, label)\n",
        "  if os.path.isdir(class_dir) and label != \".ipynb_checkpoints\":\n",
        "\n",
        "    # Create output directory\n",
        "    out_path = os.path.join(OUT_PATH, label)\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    # Go through each image in the subfolder\n",
        "    for i, filename in enumerate(os.listdir(class_dir)):\n",
        "\n",
        "      # Skip the Jupyter Notebook checkpoints folder that sometimes gets added\n",
        "      if filename != \".ipynb_checkpoints\":\n",
        "\n",
        "        # Get the root of the filename before the extension\n",
        "        file_root = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Do all transforms for that one image\n",
        "        file_path = os.path.join(DATASET_PATH, label, filename)\n",
        "        img_tfs = create_transforms(file_path)\n",
        "\n",
        "        # Save images to new files in output directory\n",
        "        for i, img in enumerate(img_tfs):\n",
        "\n",
        "          # Create a Pillow image from the Numpy array\n",
        "          img_pil = PIL.Image.fromarray(img)\n",
        "\n",
        "          # Construct filename (<orignal>_<transform_num>.<EXT>)\n",
        "          out_file_path = os.path.join(out_path, file_root + \"_\" + str(i) + IMG_EXT)\n",
        "\n",
        "          # Convert Numpy array to image and save as a file\n",
        "          img_pil = PIL.Image.fromarray(img)\n",
        "          img_pil.save(out_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWwxvzKxDJ18"
      },
      "source": [
        "### Zip our new dataset (use '!' to call Linux commands)\n",
        "!zip -r -q \"{OUT_ZIP}\" \"{OUT_PATH}\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}